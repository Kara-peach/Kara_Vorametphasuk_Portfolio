{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z88FfJc9lA_T",
   "metadata": {
    "id": "Z88FfJc9lA_T"
   },
   "source": [
    "## Analysis of an E-commerce Dataset Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoq0NwA9lA_V",
   "metadata": {
    "id": "hoq0NwA9lA_V"
   },
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd3NU_lA_W",
   "metadata": {
    "id": "f9fd3NU_lA_W"
   },
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3bd963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling all the imports will be used\n",
    "# Standard library imports\n",
    "import math\n",
    "\n",
    "# Third-party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Enable inline plotting for matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "PJrb2gtAlA_W",
   "metadata": {
    "id": "PJrb2gtAlA_W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total length of data set is 2685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4673.237616</td>\n",
       "      <td>58812.687151</td>\n",
       "      <td>3.705028</td>\n",
       "      <td>3.908007</td>\n",
       "      <td>43.478585</td>\n",
       "      <td>83.091650</td>\n",
       "      <td>19.456983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3517.893437</td>\n",
       "      <td>37013.726118</td>\n",
       "      <td>1.346240</td>\n",
       "      <td>0.289069</td>\n",
       "      <td>26.630426</td>\n",
       "      <td>42.227558</td>\n",
       "      <td>11.397281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>10100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1310.000000</td>\n",
       "      <td>22000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4666.000000</td>\n",
       "      <td>52800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>73.650000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7651.000000</td>\n",
       "      <td>91000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>129.820000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10779.000000</td>\n",
       "      <td>123199.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userId      timestamp       rating  helpfulness      item_id  \\\n",
       "count   2685.000000    2685.000000  2685.000000  2685.000000  2685.000000   \n",
       "mean    4673.237616   58812.687151     3.705028     3.908007    43.478585   \n",
       "std     3517.893437   37013.726118     1.346240     0.289069    26.630426   \n",
       "min        4.000000   10100.000000     1.000000     3.000000     0.000000   \n",
       "25%     1310.000000   22000.000000     3.000000     4.000000    21.000000   \n",
       "50%     4666.000000   52800.000000     4.000000     4.000000    42.000000   \n",
       "75%     7651.000000   91000.000000     5.000000     4.000000    67.000000   \n",
       "max    10779.000000  123199.000000     5.000000     4.000000    88.000000   \n",
       "\n",
       "        item_price    user_city  \n",
       "count  2685.000000  2685.000000  \n",
       "mean     83.091650    19.456983  \n",
       "std      42.227558    11.397281  \n",
       "min      12.000000     0.000000  \n",
       "25%      49.000000     9.000000  \n",
       "50%      73.650000    19.000000  \n",
       "75%     129.820000    28.000000  \n",
       "max     149.000000    39.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define function to read the dataset\n",
    "dataset = pd.read_csv('cleaned_ecommerce_dataset.csv')\n",
    "\n",
    "#Print out the length of analysis data\n",
    "print('The total length of data set is', len(dataset))\n",
    "\n",
    "#display dataset description ('display the DataFrame')\n",
    "dataset.head()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqbuU6rglA_X",
   "metadata": {
    "id": "aqbuU6rglA_X"
   },
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "\n",
    "  Hints: To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "W3PImHiElA_X",
   "metadata": {
    "id": "W3PImHiElA_X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  timestamp                                           review  \\\n",
       "0    4081      71900                                Not always McCrap   \n",
       "1    4081      72000  I dropped the chalupa even before he told me to   \n",
       "2    4081      72000                     The Wonderful World of Wendy   \n",
       "3    4081     100399                             They actually did it   \n",
       "4    4081     100399                             Hey! Gimme some pie!   \n",
       "\n",
       "                                 item  rating  helpfulness gender  \\\n",
       "0                          McDonald's     4.0          3.0      M   \n",
       "1                           Taco Bell     1.0          4.0      M   \n",
       "2                             Wendy's     5.0          4.0      M   \n",
       "3  South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4                        American Pie     3.0          3.0      M   \n",
       "\n",
       "                category  item_id  item_price  user_city  \n",
       "0  Restaurants & Gourmet       41       30.74          4  \n",
       "1  Restaurants & Gourmet       74      108.30          4  \n",
       "2  Restaurants & Gourmet       84       69.00          4  \n",
       "3                 Movies       68      143.11          4  \n",
       "4                 Movies        6      117.89          4  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display dataset description to have an overall picture about the data ('display the DataFrame') \n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c156802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2685 entries, 0 to 2684\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       2685 non-null   int64  \n",
      " 1   timestamp    2685 non-null   int64  \n",
      " 2   review       2685 non-null   object \n",
      " 3   item         2685 non-null   object \n",
      " 4   rating       2685 non-null   float64\n",
      " 5   helpfulness  2685 non-null   float64\n",
      " 6   gender       2685 non-null   object \n",
      " 7   category     2685 non-null   object \n",
      " 8   item_id      2685 non-null   int64  \n",
      " 9   item_price   2685 non-null   float64\n",
      " 10  user_city    2685 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 230.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the overall information of dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "423d80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Gender and Rating: -0.03433661\n",
      "Correlation between Category and Rating: -0.16315765\n",
      "Correlation between Review and Rating: -0.03611839\n",
      "Correlation between Helpfulness and Rating: -0.00752334\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Define the columns to be focused on for analysis\n",
    "focusing_columns = ['gender', 'category', 'review']\n",
    "\n",
    "# Create a copy of the dataset to perform analysis on\n",
    "analysis_data = dataset.copy()\n",
    "\n",
    "# Apply the OrdinalEncoder to the selected columns to convert categorical data to numerical format\n",
    "analysis_data[focusing_columns] = encoder.fit_transform(analysis_data[focusing_columns])\n",
    "\n",
    "# Generate a correlation matrix for all numerical features in the analysis data\n",
    "correlation_matrix = analysis_data.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "# Extract the correlations between the focused features and the 'helpfulness' against 'rating'\n",
    "focused_correlation = correlation_matrix.loc[focusing_columns + ['helpfulness'], 'rating']\n",
    "\n",
    "# Iterate over the focused correlation indices to print out the correlation values with 'rating'\n",
    "for feature in focused_correlation.index:\n",
    "    # Print the feature name (capitalized) along with its correlation to 'rating'\n",
    "    print('Correlation between %s and Rating: %.8f' % (feature.capitalize(), focused_correlation[feature]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd91d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2685 entries, 0 to 2684\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       2685 non-null   int64  \n",
      " 1   timestamp    2685 non-null   int64  \n",
      " 2   review       2685 non-null   float64\n",
      " 3   item         2685 non-null   object \n",
      " 4   rating       2685 non-null   float64\n",
      " 5   helpfulness  2685 non-null   float64\n",
      " 6   gender       2685 non-null   float64\n",
      " 7   category     2685 non-null   float64\n",
      " 8   item_id      2685 non-null   int64  \n",
      " 9   item_price   2685 non-null   float64\n",
      " 10  user_city    2685 non-null   int64  \n",
      "dtypes: float64(6), int64(4), object(1)\n",
      "memory usage: 230.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the data after converting if they are all numeric data\n",
    "analysis_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783430b",
   "metadata": {},
   "source": [
    "# Analysis correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616b704",
   "metadata": {},
   "source": [
    "The result shows the correlation coefficient (-0.007523) between \"helpfulness\" and \"rating\" is that there's essentially no linear relationship between these two variables. There appears to be no connection between the perceived helpfulness of a review and whether it has a high or low rating.\n",
    "\n",
    "It provides the inforamtion that shows the weak negative linear relationship between this two variables with the number of - 0.34337 which is close to 0 but still negative\n",
    "\n",
    "Weak Negative Correlation is seen this correlation\n",
    "\n",
    "Moreover, the most correlated feature is category\n",
    "and the least is helpfulness according to correlation result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4myP5igslA_Y",
   "metadata": {
    "id": "4myP5igslA_Y"
   },
   "source": [
    "### Split Training and Testing Data\n",
    "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
    "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
    "    * Case 1: training data containing 10% of the entire data;\n",
    "    * Case 2: training data containing 90% of the entire data.\n",
    "* Print the shape of training and testing sets in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "JIDMig9blA_Y",
   "metadata": {
    "id": "JIDMig9blA_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 - Training set shape, Testing set shape: ((268, 11), (2417, 11))\n",
      "Case 2 - Training set shape, Testing set shape: ((2416, 11), (269, 11))\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into 10% training, 90% testing for Case 1\n",
    "train_data_case1, test_data_case1 = train_test_split(analysis_data, test_size=0.9, random_state=42)\n",
    "\n",
    "# Divide the dataset into 90% training, 10% testing for Case 2\n",
    "train_data_case2, test_data_case2 = train_test_split(analysis_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Record and print the shapes of the training and testing sets for both cases to verify the splits\n",
    "shapes_case1 = (train_data_case1.shape, test_data_case1.shape)\n",
    "shapes_case2 = (train_data_case2.shape, test_data_case2.shape)\n",
    "\n",
    "# Output the shapes of the data splits to the console for inspection\n",
    "print(\"Case 1 - Training set shape, Testing set shape:\", shapes_case1)\n",
    "print(\"Case 2 - Training set shape, Testing set shape:\", shapes_case2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DjSsgT0BlA_Y",
   "metadata": {
    "id": "DjSsgT0BlA_Y"
   },
   "source": [
    "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
    "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
    "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features from helpfulness/gender/category/review regarding rating, respectively.\n",
    "* Train four linear regression models by following the conditions:\n",
    "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
    "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
    "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
    "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
    "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50ef2c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# Identify the features with the highest and lowest correlation to the target variable\n",
    "most_correlated_features = ['category', 'review']\n",
    "least_correlated_features = ['gender', 'helpfulness']\n",
    "\n",
    "# Model A: Using the most correlated features and Case 1 data split\n",
    "# Initialize the Linear Regression model\n",
    "model_a = LinearRegression()\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y) for the training data in Case 1\n",
    "X_train_case1_most = train_data_case1[most_correlated_features]\n",
    "y_train_case1 = train_data_case1['rating']\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y) for the testing data in Case 1\n",
    "X_test_case1_most = test_data_case1[most_correlated_features]\n",
    "y_test_case1 = test_data_case1['rating']\n",
    "\n",
    "# Fit Model A to the training data\n",
    "model_a.fit(X_train_case1_most, y_train_case1)\n",
    "\n",
    "# Model B: Using the least correlated features and Case 1 data split\n",
    "# Initialize another Linear Regression model for a different set of features\n",
    "model_b = LinearRegression()\n",
    "\n",
    "# Prepare the feature matrix and target vector for the training data using least correlated features\n",
    "X_train_case1_least = train_data_case1[least_correlated_features]\n",
    "y_train_case1 = train_data_case1['rating']\n",
    "\n",
    "# Similarly prepare for the testing data\n",
    "X_test_case1_least = test_data_case1[least_correlated_features]\n",
    "y_test_case1 = test_data_case1['rating']\n",
    "\n",
    "# Fit Model B to the training data\n",
    "model_b.fit(X_train_case1_least, y_train_case1)\n",
    "\n",
    "# Model C: Using the most correlated features but with Case 2 data split\n",
    "# Initialize the model\n",
    "model_c = LinearRegression()\n",
    "\n",
    "# Prepare the feature matrix and target vector for training data in Case 2\n",
    "X_train_case2_most = train_data_case2[most_correlated_features]\n",
    "y_train_case2 = train_data_case2['rating']\n",
    "\n",
    "# Prepare for testing data in Case 2\n",
    "X_test_case2_most = test_data_case2[most_correlated_features]\n",
    "y_test_case2 = test_data_case2['rating']\n",
    "\n",
    "# Fit Model C to the Case 2 training data\n",
    "model_c.fit(X_train_case2_most, y_train_case2)\n",
    "\n",
    "# Model D: Using the least correlated features and Case 2 data split\n",
    "# Initialize the model\n",
    "model_d = LinearRegression()\n",
    "\n",
    "# Prepare the feature matrix and target vector for the Case 2 training data using least correlated features\n",
    "X_train_case2_least = train_data_case2[least_correlated_features]\n",
    "y_train_case2 = train_data_case2['rating']\n",
    "\n",
    "# And for the testing data\n",
    "X_test_case2_least = test_data_case2[least_correlated_features]\n",
    "y_test_case2 = test_data_case2['rating']\n",
    "\n",
    "# Fit Model D to the Case 2 training data\n",
    "model_d.fit(X_train_case2_least, y_train_case2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "618bd6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation: I have identified that the 'review' feature may not be suitable for correlation analysis.\n",
    "# This is due to its data type being a string, which inherently lacks numeric insight for correlation calculation.\n",
    "# Despite this, the analysis necessitates selecting features with the highest and lowest correlation to 'rating'.\n",
    "# Therefore, among the available features - helpfulness, gender, category, and review - decisions were made based on their\n",
    "# respective correlation strengths with 'rating', as demonstrated in the results provided.\n",
    "# This approach underscores the importance of considering data types and their relevance in statistical analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KATSn7hYlA_Z",
   "metadata": {
    "id": "KATSn7hYlA_Z"
   },
   "source": [
    "### Evaluate Models\n",
    "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
    "* Print the results of the four models regarding the two metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb877f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model-a: MSE = 1.776581354691434 , RMSE = 1.3328845991650717\n",
      "Model-b: MSE = 1.860535990321889 , RMSE = 1.3640146591301316\n",
      "Model-c: MSE = 1.681992500504392 , RMSE = 1.2969165356739007\n",
      "Model-d: MSE = 1.7245375467700421 , RMSE = 1.3132164889194935\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Root Mean Square Error (RMSE) for each model as a measure of prediction accuracy\n",
    "# RMSE provides a scale-sensitive accuracy metric by taking the square root of the Mean Squared Error (MSE)\n",
    "rmse_model_a = math.sqrt(mse_a)\n",
    "rmse_model_b = math.sqrt(mse_b)  # Corrected typo in variable name\n",
    "rmse_model_c = math.sqrt(mse_c)\n",
    "rmse_model_d = math.sqrt(mse_d)\n",
    "\n",
    "# Output the performance metrics for each model to provide insights into their predictive accuracy\n",
    "# MSE (Mean Squared Error) indicates the average squared difference between the estimated values and the actual value\n",
    "# RMSE (Root Mean Squared Error) adjusts MSE to the scale of the data, providing a more interpretable result\n",
    "print(\"Model-a: MSE =\", mse_a, \", RMSE =\", rmse_model_a)\n",
    "print(\"Model-b: MSE =\", mse_b, \", RMSE =\", rmse_model_b)\n",
    "print(\"Model-c: MSE =\", mse_c, \", RMSE =\", rmse_model_c)\n",
    "print(\"Model-d: MSE =\", mse_d, \", RMSE =\", rmse_model_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y9jx-eY6lA_a",
   "metadata": {
    "id": "Y9jx-eY6lA_a"
   },
   "source": [
    "### Visualize, Compare and Analyze the Results\n",
    "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
    "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3TNAIGDilA_a",
   "metadata": {
    "id": "3TNAIGDilA_a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHBCAYAAACFYkGHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABN1UlEQVR4nO3de5xN9eL/8fdmroYZhswlM4NB7hJlkFsuk1sqQmrCUEnlVocml9L5HiIy5JYThjpnjBO5lIjKLZPQTCVyKOIwQ8ZlUIYxn98fPWb/2vbcLbbh9Xw81uNhf9ZnfdZn7TVrz7ytz/4smzHGCAAAAABwTUq4ugMAAAAAcCsgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcATeBuLg42Wy2XJeNGzdet323bt1arVu3vm7tS9KePXv0+uuv69ChQ07r+vXrp8qVK1/X/V+rU6dOqXfv3qpYsaJsNpsefvjhXOu2bt1aNptNVatWlTHGaf3mzZvt5zUuLs5h3fbt2/XII48oNDRUnp6eCggIUNOmTfXSSy/luI+clrzey5UrV8pms2nu3Lm51lm/fr1sNpvefvvtXOsUN6+//rrDe+Tu7q7Q0FA9/fTTSk1NdapfuXJl2Wy2XK+LxYsX53ptrlu3Th06dFBwcLA8PT0VHBys1q1b680338xxHzkthbkef/jhB/sxpaSkFHi74uTq81eqVClVqlRJkZGReuedd3Tu3DmnbXL6XMntOj506JA6d+4sf39/2Ww2DRs27PofVBH9+9//VmxsbIHrX8vn0bXI/p2W02d+frLPN1Bcubm6AwD+v4ULF6pmzZpO5bVr13ZBb6yzZ88ejR8/Xq1bt3b6g2fs2LEaOnSoazpWQH//+9/10UcfacGCBQoPD5e/v3+e9cuUKaODBw/qiy++UNu2bR3WLViwQL6+vkpPT3co/+STT/TQQw+pdevWmjx5soKCgpSSkqKdO3dqyZIlmjp1qkP9qlWr6l//+pfTvj09PXPtV+fOnRUYGKgFCxZo0KBBOdZZuHCh3N3dFRUVlecxFkdr166Vn5+fzp8/r88++0xTp07Vtm3blJycLHd3d4e6ZcqU0ebNm/Xzzz8rPDzcYV1u53Du3Ll67rnn1L17d82cOVP+/v46cuSItm3bpg8//FCvvPKKQ/3mzZtrypQpTv309fUt8DG99957kqTMzEwtXrxYo0aNKvC2xU32+bt06ZKOHTumzz//XCNHjtRbb72l1atXq0GDBva6OX2u5HYdDx8+XNu3b9eCBQsUGBiooKCgG3pchfHvf/9bu3fvLlQALMrnEYBrYAC43MKFC40ks2PHjhu+71atWplWrVpd13385z//MZLMl19+eV33c720a9fO1KpVq0B1W7VqZerUqWMiIiJMnz59HNalp6ebUqVKmaefftpIMgsXLrSva9mypQkPDzeXL192avPKlSs57qMoRo4caSSZH374wWnd6dOnjZeXl+nevXuR2v6rCxcuXHMbVnnttdeMJPPbb785lPfv399IMl988YVDeVhYmOnYsaOpVKmSefXVVx3WHThwwNhsNvs5/OvPdGhoqGnZsmWOfbj6HIaFhZnOnTtfw1EZc/HiRVO+fHnToEEDc+edd5oaNWpcU3t/lZWVZX7//XfL2rsWuZ0/Y4xJTk42fn5+JjQ01Fy8eDHPdnK7jqtVq2Y6duxoWX+v53vXuXNnExYWVuD6Rf08ulbZv9MOHjxY6G2zzzdQXDEsEChGGjZsqBYtWjiVX7lyRXfeeaceffRRe9n48ePVpEkT+fv7y9fXV/fcc4/mz5+f49CQv9q4cWOOw50OHTrkNHRk586d6t27typXrixvb29VrlxZjz/+uH799Vd7nbi4OD322GOSpDZt2jgNQclp+M7FixcVExOjKlWqyMPDQ3feeaeef/55nTlzxqFe5cqV1aVLF61du1b33HOPvL29VbNmTS1YsCDPY8x26tQpDR48WHfeeac8PDxUtWpVjR49WhkZGQ7HvGHDBu3du7dQwzSjo6O1fPlyhz4vWbJEktS7d2+n+mlpaapQoYLc3JwHFJQoYd1H9YABAyT9eYfqavHx8bp48aKio6MlScYYzZ49W3fffbe8vb1Vrlw59ejRQ7/88ovDdq1bt1bdunW1efNmNWvWTKVKlbK38cUXX6h169YqX768vL29FRoaqu7du+v333+XVLift19++UW9e/e2D7kLCAhQ27ZtlZycXKT3onHjxpKk48ePO60rUaKEnnrqKS1atEhZWVn28gULFigkJETt2rVz2iYtLS3Xux5WnsNsK1asUFpamgYOHKi+ffvqv//9r7Zu3epULyMjQ2+88YZq1aolLy8vlS9fXm3atNG2bdvsdWw2m1544QXNnTtXtWrVkqenpxYtWiRJ2rp1q9q2basyZcqoVKlSatasmT755BOHffz+++96+eWXVaVKFXl5ecnf31+NGzdWfHy8vY7V50+SGjRooNGjR+vw4cNKSEiwl//1cyWv69hms+nAgQP69NNP7eXZQ9nS09Ptx5T9OTRs2DBduHDBoQ95vXf79+9Xnz59VLFiRXl6eqpWrVqaNWuWw/bZ/YiPj9fo0aMVHBwsX19ftWvXTvv27bPXa926tT755BP9+uuvDsMkC6Kwn0dSwc67JH399ddq3ry5vLy8FBwcrJiYGF2+fDnHNhMSEtS0aVP5+PiodOnSioyMVFJSUr79z+9zBLiZEK6Am8iVK1eUmZnpsFy5csW+vn///tq6dav279/vsN1nn32mY8eOqX///vayQ4cO6dlnn9XSpUu1fPlyPfroo3rxxRf197//3bL+Hjp0SHfddZdiY2O1bt06TZo0SSkpKbr33nt18uRJSX8ORZswYYIkadasWUpMTFRiYqI6d+6cY5vGGD388MOaMmWKoqKi9Mknn2jEiBFatGiRHnjgAXvwyfbdd9/ppZde0vDhw7Vy5UrVr19fAwYM0ObNm/Ps+8WLF9WmTRstXrxYI0aM0CeffKInn3xSkydPtofUoKAgJSYmqmHDhqpataq97/fcc0++703v3r1VsmRJhz8u58+frx49euQ47Ktp06bavn27hgwZou3bt+f6x8lfXf2zkpmZ6RAEclKjRg3df//9+uCDD5z2sXDhQt15552KjIyUJD377LMaNmyY2rVrpxUrVmj27Nn68ccf1axZM6dAkpKSoieffFJ9+vTRmjVrNHjwYPt3WTw8PLRgwQKtXbtWb775pnx8fHTp0qV8j+9qnTp10q5duzR58mStX79ec+bMUcOGDZ1Cd0EdPHjQ/p7kJDo6WseOHdO6desk/Xl9Llq0SP369csxLDVt2lTLli3T66+/ru+++87h2s2JMSbHc5jff4Bkmz9/vjw9PfXEE08oOjpaNptN8+fPd6iTmZmpjh076u9//7u6dOmijz76SHFxcWrWrJkOHz7sUHfFihWaM2eOxo0bp3Xr1qlFixbatGmTHnjgAZ09e1bz589XfHy8ypQpo65duzqEmREjRmjOnDkaMmSI1q5dq/fff1+PPfaY0tLS7HWsPn/ZHnroIUnK9ZrP6zpOTExUYGCgmjdvbi8PCgrS77//rlatWmnRokUaMmSIPv30U40aNUpxcXF66KGHnM5RTu/dnj17dO+992r37t2aOnWqPv74Y3Xu3FlDhgzR+PHjnfr56quv6tdff9V7772nefPmaf/+/eratav952j27Nlq3ry5AgMD7X1NTEws0HtU2M+jgp73PXv2qG3btjpz5ozi4uI0d+5cJSUl6f/+7/+c2pwwYYIef/xx1a5dW0uXLtX777+vc+fO2d+r3Fj9OQJcd668bQbgT9lDKHJaSpYsaa938uRJ4+Hh4TRUqWfPniYgICDHIWXG/Dkk6fLly+aNN94w5cuXN1lZWfZ1Vw8L/PLLL3Mcwnfw4MF8h45kZmaa8+fPGx8fHzN9+nR7eV7DAvv27eswzGXt2rVGkpk8ebJDvYSEBCPJzJs3z14WFhZmvLy8zK+//mov++OPP4y/v7959tlnc+2nMcbMnTvXSDJLly51KJ80aZKRZD777DN7WWGG4f21bt++fU3jxo2NMcb8+OOPRpLZuHGj2bFjh9N7efLkSXP//ffbz7u7u7tp1qyZmThxojl37pzTPnL7eRkwYEC+fcz+eVu+fLm9bPfu3UaSGT16tDHGmMTERCPJTJ061WHbI0eOGG9vbzNy5Ein/nz++ecOdT/88EMjySQnJ+fal4L+vJ08edJIMrGxsfke39Wyhxmlpqaay5cvm9OnT5ulS5caHx8f8/jjjzvV/+uQvVatWpkePXoYY4z55JNPjM1mMwcPHszxZ/rAgQOmbt269nPh7e1t2rZta2bOnGkuXbrktI/czuHf//73fI/p0KFDpkSJEqZ37972slatWhkfHx+Tnp5uL1u8eLGRZP75z3/m2Z4k4+fnZ06dOuVQHhERYSpWrOjwM5iZmWnq1q1rKlWqZP8sqVu3rnn44Ydzbd+K85fTsEBj/rzmJTkM7bv6c8WY3K/jnIZoTpw40ZQoUcJpqHb2z/SaNWvsZbm9d5GRkaZSpUrm7NmzDuUvvPCC8fLystfPvgY6derkUG/p0qVGkklMTLSXFXVYoDGF+zwq6Hnv1auX8fb2NqmpqQ71atas6TAs8PDhw8bNzc28+OKLDv07d+6cCQwMND179rSXXT0ssCCfI8DNhDtXwE1k8eLF2rFjh8Oyfft2+/ry5cura9euDkOVTp8+rZUrV+qpp55yGFL2xRdfqF27dvLz81PJkiXl7u6ucePGKS0tTSdOnLCkv+fPn9eoUaNUrVo1ubm5yc3NTaVLl9aFCxe0d+/eIrX5xRdfSPpzWM9fPfbYY/Lx8dHnn3/uUH733XcrNDTU/trLy0s1atRwGJqY2358fHzUo0cPh/Ls/V69n6KIjo7Wzp079cMPP2j+/PkKDw9Xy5Ytc6xbvnx5bdmyRTt27NCbb76pbt266b///a9iYmJUr149+53AbOHh4U4/Kzt27NDYsWPz7VfPnj1VpkwZh+GTCxYskM1ms9/9/Pjjj2Wz2fTkk0863FUJDAxUgwYNnIbxlStXTg888IBD2d133y0PDw8988wzWrRokdNwwsLw9/dXeHi43nrrLb399ttKSkrK9y7d1QIDA+Xu7q5y5cqpZ8+eatSokX34Vm6io6O1atUqpaWlaf78+WrTpk2uMzKGh4fru+++06ZNmzR+/Hi1a9dOO3bs0AsvvKCmTZvq4sWLDvXvv//+HM9h9tDNvCxcuFBZWVn24ZfZfb1w4YLDnYVPP/1UXl5eDvVy88ADD6hcuXL21xcuXND27dvVo0cPlS5d2l5esmRJRUVF6X//+5992Np9992nTz/9VK+88oo2btyoP/74w6FtK85fbkwB7/QVxscff6y6devq7rvvdvj5j4yMzHEY69Xv3cWLF/X555/rkUceUalSpRza6NSpky5evKivv/7aoY3sO3DZ6tevL0n5fpYVVEE/jwpz3r/88ku1bdtWAQEBDvV69erl0Oa6deuUmZmpp556yuG98PLyUqtWrfIcam3l5whwIxCugJtIrVq11LhxY4elUaNGDnWio6N19OhRrV+/XtKf35PJyMhwCCPffPONOnToIEn65z//qa+++ko7duzQ6NGjJcnpD5+i6tOnj2bOnKmBAwdq3bp1+uabb7Rjxw7dcccdRd5HWlqa3NzcdMcddziU22w2BQYGOgwzkv4MJVfz9PTMd/9paWkKDAx0+s5CxYoV5ebm5rSfomjZsqWqV6+ud999V++//7596FZeGjdurFGjRuk///mPjh07puHDh+vQoUOaPHmyQz0vLy+nn5XGjRsrLCws336VKlVKvXv31tq1a5WamqrMzEx98MEHatWqlX1mvOPHj8sYo4CAALm7uzssX3/9tVPYy+m7RuHh4dqwYYMqVqyo559/XuHh4QoPD9f06dPz7ePVbDabPv/8c0VGRmry5Mm65557dMcdd2jIkCE5TsWdkw0bNmjHjh1at26dunfvrs2bN+vFF1/Mc5sePXrIy8tL06ZN0+rVq/MNPiVKlFDLli01btw4rVq1SseOHVOvXr20a9cup+8C+vn55XgO85utLisrS3FxcQoODlajRo105swZnTlzRu3atZOPj4/D0MDffvtNwcHBBfrO19X7PX36tIwxOfYnODhYkuzXyYwZMzRq1CitWLFCbdq0kb+/vx5++GH7EGYrzl9ussNHdp+scPz4cX3//fdOP/tlypSRMSbfn/+0tDRlZmbqnXfecWqjU6dOkuTUxtWfZdkzf1r1eV3Qz6PCnPfsz9GrXV2WPYz43nvvdXo/EhISnN6Lv7LycwS4EZiKHShmIiMjFRwcrIULFyoyMlILFy5UkyZNHKZrX7Jkidzd3fXxxx/Ly8vLXr5ixYp828+uf/V3m67+5Xf27Fl9/PHHeu211xymmM7IyNCpU6eKcmiS/vwDIzMzU7/99ptDwDLGKDU1Vffee2+R2756P9u3b5cxxuEPjBMnTigzM1MVKlSwZD/9+/fXmDFjZLPZ1Ldv30Jt6+7urtdee03Tpk3T7t27LelPtgEDBuif//ynFi9erBo1aujEiRMO071XqFBBNptNW7ZsyXF696vLcguNLVq0UIsWLXTlyhXt3LlT77zzjoYNG6aAgAD17t27wD9vkhQWFmYPDv/973+1dOlSvf7667p06VKez+7K1qBBA/t5bd++vSIjIzVv3jwNGDAg15+r7CA6ceJE+fr6OkwaUxA+Pj6KiYlRQkKCZedww4YN9kCR038ufP3119qzZ49q166tO+64Q1u3blVWVla+Aevqc1iuXDmVKFEix+dnHTt2TJLs76ePj4/Gjx+v8ePH6/jx4/a7WF27dtVPP/0k6drPX25WrVolSZY+r69ChQry9vbOdXKcqz8fcnrvsu/0PP/88zm2UaVKFWs6WwgF+TwqzHkvX758js+Ku7osu/6HH35YoP8Aulp+nyPAzYQ7V0Axk/0Le8WKFdqyZYt27tzpNOTHZrPJzc1NJUuWtJf98ccfev/99/NtP3vI0/fff+9Qnv0HzF/3YYxx+iP7vffec/oif2H+Bzb7OSwffPCBQ/myZct04cIFp+e0FFXbtm11/vx5p8C5ePFih35cq759+6pr167629/+pjvvvDPXerk9ADZ7eKWV/ysvSU2aNFHdunW1cOFCLVy4UH5+furevbt9fZcuXWSM0dGjR3O8u1KvXr1C7a9kyZJq0qSJfaa0b7/9VlLBf96uVqNGDY0ZM0b16tWzt1UYNptNs2bNUsmSJTVmzJg86z733HPq2rWrxo0b5/CfFVe7Uedw/vz5KlGihFasWKEvv/zSYcm+xrNDQceOHXXx4sUiPSDWx8dHTZo00fLlyx2u3aysLH3wwQeqVKlSjpOBBAQEqF+/fnr88ce1b9++HGd0u9bzl+27777ThAkTVLlyZfXs2bPI7VytS5cu+vnnn1W+fPkcf/7ze/B5qVKl1KZNGyUlJal+/fo5tpFTMM5PQe7K56Ugn0eFOe9t2rTR559/7jDBzZUrVxyGpkp//qegm5ubfv755xzfi+yZO/OT2+cIcDPhzhVwE9m9e7cyMzOdysPDwx3u4kRHR2vSpEnq06ePvL29nca3d+7cWW+//bb69OmjZ555RmlpaZoyZUqeD5jNFhgYqHbt2mnixIkqV66cwsLC9Pnnn2v58uUO9Xx9fdWyZUu99dZbqlChgipXrqxNmzZp/vz5Klu2rEPdunXrSpLmzZunMmXKyMvLS1WqVMnxj4vsOwqjRo1Senq6mjdvru+//16vvfaaGjZsaNnDbZ966inNmjVLffv21aFDh1SvXj1t3bpVEyZMUKdOnXKcarsogoODC3THMDIyUpUqVVLXrl1Vs2ZNZWVlKTk5WVOnTlXp0qWdHoj6xx9/OH1nI1tERESB+hYdHa0RI0Zo3759evbZZ+Xt7W1f17x5cz3zzDPq37+/du7cqZYtW8rHx0cpKSnaunWr6tWrp+eeey7P9ufOnasvvvhCnTt3VmhoqC5evGj/oz/7/S3oz9v333+vF154QY899piqV68uDw8PffHFF/r++++dHs5bUNWrV9czzzyj2bNna+vWrbr//vtzrHf33XcX6BzWqVNHbdu2VceOHRUeHq6LFy9q+/btmjp1qgICApyGFJ45cybHc+jp6amGDRvmuI+0tDStXLlSkZGR6tatW451pk2bpsWLF2vixIl6/PHHtXDhQg0aNEj79u1TmzZtlJWVpe3bt6tWrVr5/q//xIkT1b59e7Vp00Yvv/yyPDw8NHv2bO3evVvx8fH2OzZNmjRRly5dVL9+fZUrV0579+7V+++/r6ZNm6pUqVKWnL9du3bJz89Ply9ftj9E+P3331fFihW1evVqeXh4FKidghg2bJiWLVumli1bavjw4apfv76ysrJ0+PBhffbZZ3rppZfUpEmTPNuYPn267r//frVo0ULPPfecKleurHPnzunAgQNavXq1/fulhVGvXj0tX75cc+bMUaNGjVSiRIkCBxOp4J9HBT3vY8aM0apVq/TAAw9o3LhxKlWqlGbNmuU0XX3lypX1xhtvaPTo0frll1/04IMPqly5cjp+/Li++eYb+53PnBTkcwS4qbhsKg0AdnnNFqhcZvpq1qyZkWSeeOKJHNtcsGCBueuuu4ynp6epWrWqmThxopk/f77Tgx1zeohwSkqK6dGjh/H39zd+fn7mySefNDt37nSaUep///uf6d69uylXrpwpU6aMefDBB83u3btNWFiY6du3r0ObsbGxpkqVKqZkyZIO7eQ0q9cff/xhRo0aZcLCwoy7u7sJCgoyzz33nDl9+rRDvdwexFrQByOnpaWZQYMGmaCgIOPm5mbCwsJMTEyM08NIizpbYG5ymp0rISHB9OnTx1SvXt2ULl3auLu7m9DQUBMVFWX27NnjtI+8fl5ymzXyar/99pvx8PAwksw333yTY50FCxaYJk2aGB8fH+Pt7W3Cw8PNU089ZXbu3JnvMScmJppHHnnEhIWFGU9PT1O+fHnTqlUrs2rVKod6Bfl5O378uOnXr5+pWbOm8fHxMaVLlzb169c306ZNM5mZmXkeZ16zzR0/ftyULl3atGnTxl5WkAf85jRb4LvvvmseffRRU7VqVVOqVCnj4eFhwsPDzaBBg8yRI0ccts9rtsA777wz1/3GxsYaSWbFihW51smeCXPZsmXGmD+vp3Hjxpnq1asbDw8PU758efPAAw+Ybdu22beRZJ5//vkc29uyZYt54IEH7D8DERERZvXq1Q51XnnlFdO4cWNTrlw5+2fO8OHDzcmTJ40x1py/7MXT09MEBQWZDh06mOnTpzvMjpjtWmcLNMaY8+fPmzFjxpi77rrLeHh4GD8/P1OvXj0zfPhwh9nx8nrvDh48aKKjo82dd95p3N3dzR133GGaNWtm/u///s9eJ3u2wP/85z9O2179OXHq1CnTo0cPU7ZsWWOz2fJ92G5RP4+MKdh5N8aYr776ykRERBhPT08TGBho/va3v5l58+bl+BDhFStWmDZt2hhfX1/j6elpwsLCTI8ePcyGDRvsda6eLbCgnyPAzcJmzHWYZgcAAAAAbjN85woAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAAC/AQ4RxkZWXp2LFjKlOmjP1BeQAAAABuP8YYnTt3TsHBwSpRIu97U4SrHBw7dkwhISGu7gYAAACAm8SRI0dUqVKlPOsQrnJQpkwZSX++gb6+vi7uDQAAAABXSU9PV0hIiD0j5IVwlYPsoYC+vr6EKwAAAAAF+roQE1oAAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFnBzdQcAwArTT093dRcsMbTcUFd3AQAAFBF3rgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALODm6g6gYKafnu7qLlhiaLmhru4CAAAAcF249M7V5s2b1bVrVwUHB8tms2nFihV51u/Xr59sNpvTUqdOHXuduLi4HOtcvHjxOh8NAAAAgNuZS8PVhQsX1KBBA82cObNA9adPn66UlBT7cuTIEfn7++uxxx5zqOfr6+tQLyUlRV5eXtfjEAAAAABAkouHBXbs2FEdO3YscH0/Pz/5+fnZX69YsUKnT59W//79HerZbDYFBgZa1k8AAAAAyE+xntBi/vz5ateuncLCwhzKz58/r7CwMFWqVEldunRRUlJSnu1kZGQoPT3dYQEAAACAwii24SolJUWffvqpBg4c6FBes2ZNxcXFadWqVYqPj5eXl5eaN2+u/fv359rWxIkT7XfF/Pz8FBIScr27DwAAAOAWU2zDVVxcnMqWLauHH37YoTwiIkJPPvmkGjRooBYtWmjp0qWqUaOG3nnnnVzbiomJ0dmzZ+3LkSNHrnPvAQAAANxqiuVU7MYYLViwQFFRUfLw8MizbokSJXTvvffmeefK09NTnp6eVncTAAAAwG2kWN652rRpkw4cOKABAwbkW9cYo+TkZAUFBd2AngEAAAC4Xbn0ztX58+d14MAB++uDBw8qOTlZ/v7+Cg0NVUxMjI4eParFixc7bDd//nw1adJEdevWdWpz/PjxioiIUPXq1ZWenq4ZM2YoOTlZs2bNuu7HAwAAAOD25dJwtXPnTrVp08b+esSIEZKkvn37Ki4uTikpKTp8+LDDNmfPntWyZcs0ffr0HNs8c+aMnnnmGaWmpsrPz08NGzbU5s2bdd99912/AwEAAECxNv10zn9bFkdDyw11dRduWy4NV61bt5YxJtf1cXFxTmV+fn76/fffc91m2rRpmjZtmhXdAwAAAIACK5bfuQIAAACAmw3hCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALuPQ5VwAA4Ma4VR6QysNRAdzMuHMFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAVcGq42b96srl27Kjg4WDabTStWrMiz/saNG2Wz2ZyWn376yaHesmXLVLt2bXl6eqp27dr66KOPruNRAAAAAICLw9WFCxfUoEEDzZw5s1Db7du3TykpKfalevXq9nWJiYnq1auXoqKi9N133ykqKko9e/bU9u3bre4+AAAAANi5uXLnHTt2VMeOHQu9XcWKFVW2bNkc18XGxqp9+/aKiYmRJMXExGjTpk2KjY1VfHz8tXQXAAAAAHJVLL9z1bBhQwUFBalt27b68ssvHdYlJiaqQ4cODmWRkZHatm3bjewiAAAAgNuMS+9cFVZQUJDmzZunRo0aKSMjQ++//77atm2rjRs3qmXLlpKk1NRUBQQEOGwXEBCg1NTUXNvNyMhQRkaG/XV6evr1OQAAAAAAt6xiFa7uuusu3XXXXfbXTZs21ZEjRzRlyhR7uJIkm83msJ0xxqnsryZOnKjx48db32EAAAAAt41iOSzwryIiIrR//37768DAQKe7VCdOnHC6m/VXMTExOnv2rH05cuTIdesvAAAAgFtTsQ9XSUlJCgoKsr9u2rSp1q9f71Dns88+U7NmzXJtw9PTU76+vg4LAAAAABSGS4cFnj9/XgcOHLC/PnjwoJKTk+Xv76/Q0FDFxMTo6NGjWrx4saQ/ZwKsXLmy6tSpo0uXLumDDz7QsmXLtGzZMnsbQ4cOVcuWLTVp0iR169ZNK1eu1IYNG7R169YbfnwAAAAAbh8uDVc7d+5UmzZt7K9HjBghSerbt6/i4uKUkpKiw4cP29dfunRJL7/8so4ePSpvb2/VqVNHn3zyiTp16mSv06xZMy1ZskRjxozR2LFjFR4eroSEBDVp0uTGHRgAAACA245Lw1Xr1q1ljMl1fVxcnMPrkSNHauTIkfm226NHD/Xo0eNauwcAAAAABVbsv3MFAAAAADcDwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAF3FzdAQDA/7d8X4qru2CJR+8KcnUXAAC44bhzBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFmIodNxTTTAMAAOBWxZ0rAAAAALAA4QoAAAAALMCwQAAAAOAWwtcwXIc7VwAAAABgAcIVAAAAAFiAcAUAAAAAFuA7VwAAoNi4Vb5LIhXP75MAyBt3rgAAAADAAoQrAAAAALAA4QoAAAAALODScLV582Z17dpVwcHBstlsWrFiRZ71ly9frvbt2+uOO+6Qr6+vmjZtqnXr1jnUiYuLk81mc1ouXrx4HY8EAAAAwO3OpeHqwoULatCggWbOnFmg+ps3b1b79u21Zs0a7dq1S23atFHXrl2VlJTkUM/X11cpKSkOi5eX1/U4BAAAAACQ5OLZAjt27KiOHTsWuH5sbKzD6wkTJmjlypVavXq1GjZsaC+32WwKDAy0qpsAAAAAkK9i/Z2rrKwsnTt3Tv7+/g7l58+fV1hYmCpVqqQuXbo43dkCAAAAAKsV63A1depUXbhwQT179rSX1axZU3FxcVq1apXi4+Pl5eWl5s2ba//+/bm2k5GRofT0dIcFAAAAAAqj2D5EOD4+Xq+//rpWrlypihUr2ssjIiIUERFhf928eXPdc889eueddzRjxowc25o4caLGjx9/3fsMAAAA4NZVLO9cJSQkaMCAAVq6dKnatWuXZ90SJUro3nvvzfPOVUxMjM6ePWtfjhw5YnWXAQAAANziit2dq/j4eEVHRys+Pl6dO3fOt74xRsnJyapXr16udTw9PeXp6WllNwEAAADcZlwars6fP68DBw7YXx88eFDJycny9/dXaGioYmJidPToUS1evFjSn8Hqqaee0vTp0xUREaHU1FRJkre3t/z8/CRJ48ePV0REhKpXr6709HTNmDFDycnJmjVr1o0/QAAAAAC3DZcOC9y5c6caNmxon0Z9xIgRatiwocaNGydJSklJ0eHDh+313333XWVmZur5559XUFCQfRk6dKi9zpkzZ/TMM8+oVq1a6tChg44eParNmzfrvvvuu7EHBwAAAOC24tI7V61bt5YxJtf1cXFxDq83btyYb5vTpk3TtGnTrrFnAAAAAFA4xXJCCwAAAAC42RCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKFDleZmZlyc3PT7t27r0d/AAAAAKBYKnS4cnNzU1hYmK5cuXI9+gMAAAAAxVKRhgWOGTNGMTExOnXqlNX9AQAAAIBiya0oG82YMUMHDhxQcHCwwsLC5OPj47D+22+/taRzAAAAAFBcFClcPfzwwxZ3AwAAAACKtyKFq9dee82SnW/evFlvvfWWdu3apZSUFH300Uf5BrdNmzZpxIgR+vHHHxUcHKyRI0dq0KBBDnWWLVumsWPH6ueff1Z4eLj+8Y9/6JFHHrGkzwAAAACQk2uain3Xrl364IMP9K9//UtJSUmF3v7ChQtq0KCBZs6cWaD6Bw8eVKdOndSiRQslJSXp1Vdf1ZAhQ7Rs2TJ7ncTERPXq1UtRUVH67rvvFBUVpZ49e2r79u2F7h8AAAAAFFSR7lydOHFCvXv31saNG1W2bFkZY3T27Fm1adNGS5Ys0R133FGgdjp27KiOHTsWeL9z585VaGioYmNjJUm1atXSzp07NWXKFHXv3l2SFBsbq/bt2ysmJkaSFBMTo02bNik2Nlbx8fGFO1AAAAAAKKAi3bl68cUXlZ6erh9//FGnTp3S6dOntXv3bqWnp2vIkCFW99EuMTFRHTp0cCiLjIzUzp07dfny5TzrbNu2Ldd2MzIylJ6e7rAAAAAAQGEUKVytXbtWc+bMUa1atexltWvX1qxZs/Tpp59a1rmrpaamKiAgwKEsICBAmZmZOnnyZJ51UlNTc2134sSJ8vPzsy8hISHWdx4AAADALa1I4SorK0vu7u5O5e7u7srKyrrmTuXFZrM5vDbGOJXnVOfqsr+KiYnR2bNn7cuRI0cs7DEAAACA20GRwtUDDzygoUOH6tixY/ayo0ePavjw4Wrbtq1lnbtaYGCg0x2oEydOyM3NTeXLl8+zztV3s/7K09NTvr6+DgsAAAAAFEaRwtXMmTN17tw5Va5cWeHh4apWrZqqVKmic+fO6Z133rG6j3ZNmzbV+vXrHco+++wzNW7c2H4nLbc6zZo1u279AgAAAIAizRYYEhKib7/9VuvXr9dPP/0kY4xq166tdu3aFaqd8+fP68CBA/bXBw8eVHJysvz9/RUaGqqYmBgdPXpUixcvliQNGjRIM2fO1IgRI/T0008rMTFR8+fPd5gFcOjQoWrZsqUmTZqkbt26aeXKldqwYYO2bt1alEMFAAAAgAIpdLjKzMyUl5eXkpOT1b59e7Vv377IO9+5c6fatGljfz1ixAhJUt++fRUXF6eUlBQdPnzYvr5KlSpas2aNhg8frlmzZik4OFgzZsywT8MuSc2aNdOSJUs0ZswYjR07VuHh4UpISFCTJk2K3E8AAAAAyE+hw5Wbm5vCwsJ05cqVa95569at7RNS5CQuLs6prFWrVvr222/zbLdHjx7q0aPHtXYPAAAAAAqsSN+5GjNmjGJiYnTq1Cmr+wMAAAAAxVKRvnM1Y8YMHThwQMHBwQoLC5OPj4/D+vzuLAEAAADAraZI4erhhx+2uBsAAAAAULwVaUILSYqOjlZISIjlHQIAAACA4qjQ37lyc3PTlClTLJnQAgAAAABuFUWa0KJt27bauHGjxV0BAAAAgOKrSN+56tixo2JiYrR79241atTIaUKLhx56yJLOAQAAAEBxUaRw9dxzz0mS3n77bad1NpuNIYMAAAAAbjtFCldZWVlW9wMAAAAAirVCfeeqU6dOOnv2rP31P/7xD505c8b+Oi0tTbVr17ascwAAAABQXBQqXK1bt04ZGRn215MmTdKpU6fsrzMzM7Vv3z7regcAAAAAxUShwpUxJs/XAAAAAHC7KtJU7AAAAAAAR4UKVzabTTabzakMAAAAAG53hZot0Bijfv36ydPTU5J08eJFDRo0yP6cq79+HwsAAAAAbieFCld9+/Z1eP3kk0861XnqqaeurUcAAAAAUAwVKlwtXLjwevUDAAAAAIo1JrQAAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAAC7g8XM2ePVtVqlSRl5eXGjVqpC1btuRat1+/frLZbE5LnTp17HXi4uJyrHPx4sUbcTgAAAAAblMuDVcJCQkaNmyYRo8eraSkJLVo0UIdO3bU4cOHc6w/ffp0paSk2JcjR47I399fjz32mEM9X19fh3opKSny8vK6EYcEAAAA4Dbl0nD19ttva8CAARo4cKBq1aql2NhYhYSEaM6cOTnW9/PzU2BgoH3ZuXOnTp8+rf79+zvUs9lsDvUCAwNvxOEAAAAAuI25LFxdunRJu3btUocOHRzKO3TooG3bthWojfnz56tdu3YKCwtzKD9//rzCwsJUqVIldenSRUlJSXm2k5GRofT0dIcFAAAAAArDZeHq5MmTunLligICAhzKAwIClJqamu/2KSkp+vTTTzVw4ECH8po1ayouLk6rVq1SfHy8vLy81Lx5c+3fvz/XtiZOnCg/Pz/7EhISUrSDAgAAAHDbcvmEFjabzeG1McapLCdxcXEqW7asHn74YYfyiIgIPfnkk2rQoIFatGihpUuXqkaNGnrnnXdybSsmJkZnz561L0eOHCnSsQAAAAC4fbm5ascVKlRQyZIlne5SnThxwulu1tWMMVqwYIGioqLk4eGRZ90SJUro3nvvzfPOlaenpzw9PQveeQAAAAC4isvuXHl4eKhRo0Zav369Q/n69evVrFmzPLfdtGmTDhw4oAEDBuS7H2OMkpOTFRQUdE39BQAAAIC8uOzOlSSNGDFCUVFRaty4sZo2bap58+bp8OHDGjRokKQ/h+sdPXpUixcvdthu/vz5atKkierWrevU5vjx4xUREaHq1asrPT1dM2bMUHJysmbNmnVDjgkAAADA7cml4apXr15KS0vTG2+8oZSUFNWtW1dr1qyxz/6XkpLi9Myrs2fPatmyZZo+fXqObZ45c0bPPPOMUlNT5efnp4YNG2rz5s267777rvvxAAAAALh9uTRcSdLgwYM1ePDgHNfFxcU5lfn5+en333/Ptb1p06Zp2rRpVnUPAAAAAArE5bMFAgAAAMCtgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABYgXAEAAACABQhXAAAAAGABwhUAAAAAWIBwBQAAAAAWIFwBAAAAgAUIVwAAAABgAcIVAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFAAAAABZwebiaPXu2qlSpIi8vLzVq1EhbtmzJte7GjRtls9mclp9++smh3rJly1S7dm15enqqdu3a+uijj673YQAAAAC4zbk0XCUkJGjYsGEaPXq0kpKS1KJFC3Xs2FGHDx/Oc7t9+/YpJSXFvlSvXt2+LjExUb169VJUVJS+++47RUVFqWfPntq+ffv1PhwAAAAAtzGXhqu3335bAwYM0MCBA1WrVi3FxsYqJCREc+bMyXO7ihUrKjAw0L6ULFnSvi42Nlbt27dXTEyMatasqZiYGLVt21axsbHX+WgAAAAA3M5cFq4uXbqkXbt2qUOHDg7lHTp00LZt2/LctmHDhgoKClLbtm315ZdfOqxLTEx0ajMyMjLfNgEAAADgWri5ascnT57UlStXFBAQ4FAeEBCg1NTUHLcJCgrSvHnz1KhRI2VkZOj9999X27ZttXHjRrVs2VKSlJqaWqg2JSkjI0MZGRn21+np6UU9LAAAAAC3KZeFq2w2m83htTHGqSzbXXfdpbvuusv+umnTpjpy5IimTJliD1eFbVOSJk6cqPHjxxel+wAAAAAgyYXDAitUqKCSJUs63VE6ceKE052nvERERGj//v3214GBgYVuMyYmRmfPnrUvR44cKfD+AQAAAEByYbjy8PBQo0aNtH79eofy9evXq1mzZgVuJykpSUFBQfbXTZs2dWrzs88+y7NNT09P+fr6OiwAAAAAUBguHRY4YsQIRUVFqXHjxmratKnmzZunw4cPa9CgQZL+vKN09OhRLV68WNKfMwFWrlxZderU0aVLl/TBBx9o2bJlWrZsmb3NoUOHqmXLlpo0aZK6deumlStXasOGDdq6datLjhEAAADA7cGl4apXr15KS0vTG2+8oZSUFNWtW1dr1qxRWFiYJCklJcXhmVeXLl3Syy+/rKNHj8rb21t16tTRJ598ok6dOtnrNGvWTEuWLNGYMWM0duxYhYeHKyEhQU2aNLnhxwcAAADg9uHyCS0GDx6swYMH57guLi7O4fXIkSM1cuTIfNvs0aOHevToYUX3AAAAAKBAXPoQYQAAAAC4VRCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAsQLgCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMACbq7uAADg9nPlyhVdvnzZ1d245Xh4eKhECf7fFABcxeXhavbs2XrrrbeUkpKiOnXqKDY2Vi1atMix7vLlyzVnzhwlJycrIyNDderU0euvv67IyEh7nbi4OPXv399p2z/++ENeXl7X7TgAAPkzxig1NVVnzpxxdVduSSVKlFCVKlXk4eHh6q4AwG3JpeEqISFBw4YN0+zZs9W8eXO9++676tixo/bs2aPQ0FCn+ps3b1b79u01YcIElS1bVgsXLlTXrl21fft2NWzY0F7P19dX+/btc9iWYAUArpcdrCpWrKhSpUrJZrO5uku3jKysLB07dkwpKSkKDQ3lvQUAF3BpuHr77bc1YMAADRw4UJIUGxurdevWac6cOZo4caJT/djYWIfXEyZM0MqVK7V69WqHcGWz2RQYGHhd+w4AKJwrV67Yg1X58uVd3Z1b0h133KFjx44pMzNT7u7uru4OANx2XDYw+9KlS9q1a5c6dOjgUN6hQwdt27atQG1kZWXp3Llz8vf3dyg/f/68wsLCVKlSJXXp0kVJSUl5tpORkaH09HSHBQBgrezvWJUqVcrFPbl1ZQ8HvHLliot7AgC3J5eFq5MnT+rKlSsKCAhwKA8ICFBqamqB2pg6daouXLignj172stq1qypuLg4rVq1SvHx8fLy8lLz5s21f//+XNuZOHGi/Pz87EtISEjRDgoAkC+Gq10/vLcA4Foun1Lo6l8ExpgC/XKIj4/X66+/roSEBFWsWNFeHhERoSeffFINGjRQixYttHTpUtWoUUPvvPNOrm3FxMTo7Nmz9uXIkSNFPyAAAAAAtyWXfeeqQoUKKlmypNNdqhMnTjjdzbpaQkKCBgwYoP/85z9q165dnnVLlCihe++9N887V56envL09Cx45wEAAADgKi4LVx4eHmrUqJHWr1+vRx55xF6+fv16devWLdft4uPjFR0drfj4eHXu3Dnf/RhjlJycrHr16lnSbwCA9aafnn7D9jW03NBCb9OvXz8tWrRIzz77rObOneuwbvDgwZozZ4769u2ruLg4nThxQmPHjtWnn36q48ePq1y5cmrQoIFef/11NW3aVJJUuXJl/frrr077mThxol555ZWiHRgAwOVcOlvgiBEjFBUVpcaNG6tp06aaN2+eDh8+rEGDBkn6c7je0aNHtXjxYkl/BqunnnpK06dPV0REhP2ul7e3t/z8/CRJ48ePV0REhKpXr6709HTNmDFDycnJmjVrlmsOEgBwSwgJCdGSJUs0bdo0eXt7S5IuXryo+Ph4h8eHdO/eXZcvX9aiRYtUtWpVHT9+XJ9//rlOnTrl0N4bb7yhp59+2qGsTJky1/9AAADXjUvDVa9evZSWlqY33nhDKSkpqlu3rtasWaOwsDBJUkpKig4fPmyv/+677yozM1PPP/+8nn/+eXt59v8WStKZM2f0zDPPKDU1VX5+fmrYsKE2b96s++6774YeGwDg1nLPPffol19+0fLly/XEE09I+vPh9iEhIapataqkP38Hbd26VRs3blSrVq0kSWFhYTn+DipTpgyPDQGAW4xLw5X053CKwYMH57guOzBl27hxY77tTZs2TdOmTbOgZwAAOOrfv78WLlxoD1cLFixQdHS0/fdT6dKlVbp0aa1YsUIRERF8nxcAbjMuny0QAIDiIioqSlu3btWhQ4f066+/6quvvtKTTz5pX+/m5qa4uDgtWrRIZcuWVfPmzfXqq6/q+++/d2pr1KhR9jCWvRTkPxEBADcvl9+5AgCguKhQoYI6d+6sRYsWyRijzp07q0KFCg51unfvrs6dO2vLli1KTEzU2rVrNXnyZL333nvq16+fvd7f/vY3h9eSdOedd96AowAAXC+EKwAACiE6OlovvPCCJOU6WZKXl5fat2+v9u3ba9y4cRo4cKBee+01hzBVoUIFVatW7UZ0GQBwgzAsEACAQnjwwQd16dIlXbp0SZGRkQXapnbt2rpw4cJ17hkAwNW4cwUAQCGULFlSe/futf/7r9LS0vTYY48pOjpa9evXV5kyZbRz505NnjzZ6RmO586dsz9SJFupUqXk6+t7fQ8AAHDdEK4AACik3AJQ6dKl1aRJE02bNk0///yzLl++rJCQED399NN69dVXHeqOGzdO48aNcyjL6SHFAIDig3AFAHC5oeWGuroLebr60SBXW7Fihf3fEydO1MSJE/Osf+jQoWvvFADgpsN3rgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsICbqzsAAMDyfSk3bF+P3hVU6G369eunRYsWSZJKliyp4OBgde7cWRMmTFC5cuUkSZUrV9avv/6q+Ph49e7d22H7OnXqaM+ePVq4cKH69esnSUpKStLYsWP1zTffKD09XYGBgWrSpIlmzZqlChUq6NChQ6pSpUqO/UlMTFREREShjwMAcH1x5woAgAJ48MEHlZKSokOHDum9997T6tWrNXjwYIc6ISEhWrhwoUPZ119/rdTUVPn4+NjLTpw4oXbt2qlChQpat26d9u7dqwULFigoKEi///67w/YbNmxQSkqKw9KoUaPrd6AAgCLjzhUAAAXg6empwMBASVKlSpXUq1cvxcXFOdR54oknNG3aNB05ckQhISGSpAULFuiJJ57Q4sWL7fW2bdum9PR0vffee3Jz+/NXcZUqVfTAAw847bd8+fL2/QIAbm7cuQIAoJB++eUXrV27Vu7u7g7lAQEBioyMtA8h/P3335WQkKDo6GiHeoGBgcrMzNRHH30kY8wN6zcA4PoiXAEAUAAff/yxSpcuLW9vb4WHh2vPnj0aNWqUU73o6GjFxcXJGKMPP/xQ4eHhuvvuux3qRERE6NVXX1WfPn1UoUIFdezYUW+99ZaOHz/u1F6zZs1UunRph+XKlSvX6zABANeAcAUAQAG0adNGycnJ2r59u1588UVFRkbqxRdfdKrXuXNnnT9/Xps3b9aCBQuc7lpl+8c//qHU1FTNnTtXtWvX1ty5c1WzZk398MMPDvUSEhKUnJzssJQsWfK6HCMA4NoQrgAAKAAfHx9Vq1ZN9evX14wZM5SRkaHx48c71XNzc1NUVJRee+01bd++XU888USubZYvX16PPfaYpk6dqr179yo4OFhTpkxxqBMSEqJq1ao5LACAmxPhCgCAInjttdc0ZcoUHTt2zGlddHS0Nm3apG7dutmnas+Ph4eHwsPDdeHCBau7CgC4QZgtEACAImjdurXq1KmjCRMmaObMmQ7ratWqpZMnT6pUqVI5bvvxxx9ryZIl6t27t2rUqCFjjFavXq01a9Y4TeWelpam1NRUh7KyZcvKy8vL2gMCAFwzwhUAAEU0YsQI9e/fP8eJLcqXL5/rdrVr11apUqX00ksv6ciRI/L09FT16tX13nvvKSoqyqFuu3btnLbP6UHFAADXI1wBAFzu0buCXN2FPF39PKtsffr0UZ8+fSRJhw4dyrONM2fO2P9dtWpVzZs3L8/6lStXZpp2AChm+M4VAAAAAFiAcAUAAAAAFiBcAQAAAIAFCFcAAAAAYAHCFQAAAABYgHAFALihsrKyXN2FWxazCwKAazEVOwDghvDw8FCJEiV07Ngx3XHHHfLw8JDNZnN1t24Zxhj99ttvstlscnd3d3V3AOC2RLgCANwQJUqUUJUqVZSSkqJjx465uju3JJvNpkqVKqlkyZKu7goA3JYIVwCAG8bDw0OhoaHKzMzUlStXXN2dW467uzvBCgBciHAFALihsoetMXQNAHCrcfmEFrNnz1aVKlXk5eWlRo0aacuWLXnW37Rpkxo1aiQvLy9VrVpVc+fOdaqzbNky1a5dW56enqpdu7Y++uij69V9AAAAAJDk4nCVkJCgYcOGafTo0UpKSlKLFi3UsWNHHT58OMf6Bw8eVKdOndSiRQslJSXp1Vdf1ZAhQ7Rs2TJ7ncTERPXq1UtRUVH67rvvFBUVpZ49e2r79u036rAAAAAA3IZcGq7efvttDRgwQAMHDlStWrUUGxurkJAQzZkzJ8f6c+fOVWhoqGJjY1WrVi0NHDhQ0dHRmjJlir1ObGys2rdvr5iYGNWsWVMxMTFq27atYmNjb9BRAQAAALgduew7V5cuXdKuXbv0yiuvOJR36NBB27Zty3GbxMREdejQwaEsMjJS8+fP1+XLl+Xu7q7ExEQNHz7cqU5e4SojI0MZGRn212fPnpUkpaenF+aQrquL6Rdd3QVL/H7+nKu7YIn0dB9XdwFX4Rq5uXCN3Hy4Rm4+XCc3l1vlGpFunevkZrlGsjNBQZ4l6LJwdfLkSV25ckUBAQEO5QEBAUpNTc1xm9TU1BzrZ2Zm6uTJkwoKCsq1Tm5tStLEiRM1fvx4p/KQkJCCHg4K7JX8qwC3Na4RIG9cI0D+uE6uh3PnzsnPzy/POi6fLfDqB0gaY/J8qGRO9a8uL2ybMTExGjFihP11VlaWTp06pfLly/OASwulp6crJCRER44cka+vr6u7A9x0uEaAvHGNAPnjOrGeMUbnzp1TcHBwvnVdFq4qVKigkiVLOt1ROnHihNOdp2yBgYE51ndzc1P58uXzrJNbm5Lk6ekpT09Ph7KyZcsW9FBQSL6+vlzsQB64RoC8cY0A+eM6sVZ+d6yyuWxCCw8PDzVq1Ejr1693KF+/fr2aNWuW4zZNmzZ1qv/ZZ5+pcePG9uel5FYntzYBAAAAwAouHRY4YsQIRUVFqXHjxmratKnmzZunw4cPa9CgQZL+HK539OhRLV68WJI0aNAgzZw5UyNGjNDTTz+txMREzZ8/X/Hx8fY2hw4dqpYtW2rSpEnq1q2bVq5cqQ0bNmjr1q0uOUYAAAAAtweXhqtevXopLS1Nb7zxhlJSUlS3bl2tWbNGYWFhkqSUlBSHZ15VqVJFa9as0fDhwzVr1iwFBwdrxowZ6t69u71Os2bNtGTJEo0ZM0Zjx45VeHi4EhIS1KRJkxt+fHDk6emp1157zWkIJoA/cY0AeeMaAfLHdeJaNlOQOQUBAAAAAHly6UOEAQAAAOBWQbgCAAAAAAsQrgAAAADAAoQr3BAbN26UzWbTmTNnCrxN5cqVFRsbe936BNxMrsc1cujQIdlsNiUnJ19z/4CbAb9LgNzdqOuD3y15I1xBktSvXz/ZbDb7NPh/NXjwYNlsNvXr1+/Gdwy4SXCNAPnjOgFyx/VxeyBcwS4kJERLlizRH3/8YS+7ePGi4uPjFRoa6sKeATcHrhEgf1wnQO64Pm59hCvY3XPPPQoNDdXy5cvtZcuXL1dISIgaNmxoL8vIyNCQIUNUsWJFeXl56f7779eOHTsc2lqzZo1q1Kghb29vtWnTRocOHXLa37Zt29SyZUt5e3srJCREQ4YM0YULFwrV51GjRqlGjRoqVaqUqlatqrFjx+ry5cuFO3CggIrjNSJJP/30k5o1ayYvLy/VqVNHGzduLHQbQEEVx+vkf//7n3r37i1/f3/5+PiocePG2r59e+EOHCiA4nh9fPPNN2rYsKG8vLzUuHFjJSUlFe6gbzOEKzjo37+/Fi5caH+9YMECRUdHO9QZOXKkli1bpkWLFunbb79VtWrVFBkZqVOnTkmSjhw5okcffVSdOnVScnKyBg4cqFdeecWhjR9++EGRkZF69NFH9f333yshIUFbt27VCy+8UKj+lilTRnFxcdqzZ4+mT5+uf/7zn5o2bVoRjx7IX3G7RiTpb3/7m1566SUlJSWpWbNmeuihh5SWllaEowcKpjhdJ+fPn1erVq107NgxrVq1St99951GjhyprKysa3gHgNwVp+vjwoUL6tKli+666y7t2rVLr7/+ul5++eVrOPrbgAGMMX379jXdunUzv/32m/H09DQHDx40hw4dMl5eXua3334z3bp1M3379jXnz5837u7u5l//+pd920uXLpng4GAzefJkY4wxMTExplatWiYrK8teZ9SoUUaSOX36tDHGmKioKPPMM8849GHLli2mRIkS5o8//jDGGBMWFmamTZtWqOOYPHmyadSoURHeASBvxfEaOXjwoJFk3nzzTXvZ5cuXTaVKlcykSZOu9S0BnBTH6+Tdd981ZcqUMWlpaRa9C0DOiuv14e/vby5cuGAvmzNnjpFkkpKSrvEduTW5uTLY4eZToUIFde7cWYsWLZIxRp07d1aFChXs63/++WddvnxZzZs3t5e5u7vrvvvu0969eyVJe/fuVUREhGw2m71O06ZNHfaza9cuHThwQP/617/sZcYYZWVl6eDBg6pVq5ZD/UGDBumDDz6wvz5//rwk6cMPP1RsbKwOHDig8+fPKzMzU76+vha8E0DOits1cnXbbm5uaty4sb0vwPVQnK6T5ORkNWzYUP7+/tYcPJCP4nR97N27Vw0aNFCpUqVy3Q8cEa7gJDo62n7LeNasWQ7rjDGS5HAxZ5dnl2XXyUtWVpaeffZZDRkyxGldTl/ofOONN5xuQ3/99dfq3bu3xo8fr8jISPn5+WnJkiWaOnVqvvsHrkVxuUbycnX/AKsVl+vE29s73/0AVisu10dB9gNHhCs4efDBB3Xp0iVJUmRkpMO6atWqycPDQ1u3blWfPn0kSZcvX9bOnTs1bNgwSVLt2rW1YsUKh+2+/vprh9f33HOPfvzxR1WrVq1AfapYsaIqVqzoUPbVV18pLCxMo0ePtpf9+uuvBWoPuBbF5Rr5a9stW7aUJGVmZmrXrl1F+u4WUBjF5TqpX7++3nvvPZ06dYq7V7hhisv1Ubt2bb3//vv6448/7P8RcfV+4IgJLeCkZMmS2rt3r/bu3auSJUs6rPPx8dFzzz2nv/3tb1q7dq327Nmjp59+Wr///rsGDBgg6c/byj///LNGjBihffv26d///rfi4uIc2hk1apQSExP1/PPPKzk5Wfv379eqVav04osvFrif1apV0+HDh7VkyRL9/PPPmjFjhj766KNrPn4gP8XlGsk2a9YsffTRR/rpp5/0/PPP6/Tp005fngasVlyuk8cff1yBgYF6+OGH9dVXX+mXX37RsmXLlJiYeM3vAZCb4nJ99OnTRyVKlNCAAQO0Z88erVmzRlOmTLnm47+VEa6QI19f31y/u/Tmm2+qe/fuioqK0j333KMDBw5o3bp1KleunKQ/bzUvW7ZMq1evVoMGDTR37lxNmDDBoY369etr06ZN2r9/v1q0aKGGDRtq7NixCgoKKnAfu3XrpuHDh+uFF17Q3XffrW3btmns2LFFP2igEIrDNfLX/kyaNEkNGjTQli1btHLlSofx/cD1UhyuEw8PD3322WeqWLGiOnXqpHr16unNN990+oMXsFpxuD5Kly6t1atXa8+ePWrYsKFGjx6tSZMmFf2gbwM2w2BKAAAAALhm3LkCAAAAAAsQrgAAAADAAoQrAAAAALAA4QoAAAAALEC4AgAAAAALEK4AAAAAwAKEKwAAAACwAOEKAAAAACxAuAIAAAAACxCuAAAAAMAChCsAAAAAsADhCgAAAAAs8P8AQD8o2k7NWMwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare the data for visualization.\n",
    "# calculated from previous evaluations of four different models. Similarly, rmse_a, rmse_b, rmse_c, and rmse_d \n",
    "# are the corresponding Root Mean Squared Error (RMSE) values.\n",
    "mse_values = [mse_a, mse_b, mse_c, mse_d]\n",
    "rmse_values = [rmse_a, rmse_b, rmse_c, rmse_d]\n",
    "model_labels = ['Model-a', 'Model-b', 'Model-c', 'Model-d']\n",
    "\n",
    "# Define the positions for the bar chart and the width of each bar to differentiate between the MSE and RMSE values visually.\n",
    "pos = np.arange(len(model_labels))\n",
    "width = 0.25  # Optimal width for clear distinction between bars\n",
    "\n",
    "# Initialize a figure for plotting with a specified size to ensure clarity and sufficient space for all elements.\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the MSE values for each model using light green bars.\n",
    "# The bars are positioned to the left of the center for each model label by subtracting half the width.\n",
    "plt.bar(pos - width/2, mse_values, width, label='MSE', color='lightgreen')\n",
    "\n",
    "# Plot the RMSE values for each model using light blue bars.\n",
    "# These bars are positioned to the right of the center by adding half the width, creating a side-by-side comparison.\n",
    "plt.bar(pos + width/2, rmse_values, width, label='RMSE', color='lightblue')\n",
    "\n",
    "# Enhance the chart with a title, labels, and a legend.\n",
    "# This includes setting y-axis label as 'Error', adding a descriptive title, and customizing tick labels on the x-axis.\n",
    "plt.ylabel('Error')\n",
    "plt.title('Evaluation of MSE Versus RMSE Across Different Models')\n",
    "plt.xticks(pos, model_labels)\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot. This visual comparison facilitates a clearer understanding of the models' performance metrics.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee01ac",
   "metadata": {
    "id": "f9ee01ac"
   },
   "source": [
    "### Data Science Ethics\n",
    "*Please read the following examples [Click here to read the example_1.](https://www.vox.com/covid-19-coronavirus-us-response-trump/2020/5/18/21262265/georgia-covid-19-cases-declining-reopening) [Click here to read the example_2.](https://viborc.com/ethics-and-ethical-data-visualization-a-complete-guide/)\n",
    "\n",
    "*Then view the picture ![My Image](figure_portfolio2.png \"This is my image\")\n",
    "Please compose an analysis of 100-200 words that evaluates potential ethical concerns associated with the infographic, detailing the reasons behind these issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d172177a",
   "metadata": {
    "id": "44f30e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lenght of the answer is 166 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The two medal tables from the 2008 Summer Olympics demonstrate alternate ranking methods. Table 1 lists countries by their total medal haul, with the United States at the top due to the sum of their medals. Table 2 uses a 'gold first' system that places China ahead because of their superior gold medal count. These rankings affect perceptions of Olympic success. Traditionally, the gold-first method is preferred to decide the leading nation; thus, China is viewed as the victor in Table 2. In cases where gold, silver, and bronze counts are equal, the IOC's rule is to order countries alphabetically by IOC country code. The discrepancy between these tables can send conflicting messages about which country truly 'led' the Olympics, hinging on whether total medals or golds are emphasized. It's crucial to present this data neutrally for a clear understanding of the outcomes. This summary provides an objective look at how different presentation methods can influence interpretations of Olympic success, while adhering to IOC tie-breaking procedures.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the answer into a string variable to present and print out the lenght of answer\n",
    "\n",
    "answer_datascience_ethics = (\"The two medal tables from the 2008 Summer Olympics demonstrate alternate ranking methods. \"\n",
    "                   \"Table 1 lists countries by their total medal haul, with the United States at the top due to the sum \"\n",
    "                   \"of their medals. Table 2 uses a 'gold first' system that places China ahead because of their superior \"\n",
    "                   \"gold medal count. These rankings affect perceptions of Olympic success. Traditionally, the gold-first \"\n",
    "                   \"method is preferred to decide the leading nation; thus, China is viewed as the victor in Table 2. In \"\n",
    "                   \"cases where gold, silver, and bronze counts are equal, the IOC's rule is to order countries alphabetically \"\n",
    "                   \"by IOC country code. The discrepancy between these tables can send conflicting messages about which \"\n",
    "                   \"country truly 'led' the Olympics, hinging on whether total medals or golds are emphasized. It's crucial \"\n",
    "                   \"to present this data neutrally for a clear understanding of the outcomes. This summary provides an \"\n",
    "                   \"objective look at how different presentation methods can influence interpretations of Olympic success, \"\n",
    "                   \"while adhering to IOC tie-breaking procedures.\")\n",
    "\n",
    "print(\"The lenght of the answer is\" ,len(answer_datascience_ethics.split()), \"words\")\n",
    "\n",
    "\n",
    "answer_datascience_ethics\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
